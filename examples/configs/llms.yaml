# config llm here
openai_llm:
  initializer: llm
  data:
    provider: openai
    tag: llm
    model: gpt-3.5-turbo
    temperature: 0.7
    api_key: !ENV ${OPENAI_API_KEY}
    base_url: !ENV ${OPENAI_API_BASE}

# or reference from settings (settings.yaml)
openai_chat: !SET ${templates.llm_openai_chat}