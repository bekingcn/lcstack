# reference from settings (settings.yaml)
tavily_search: !SET ${templates.tools.tavily_search}

tool_node:
  initializer: tool_node
  data:
    tools:
      - '{{ tavily_search }}'

llm_with_tools:
  initializer: llm
  data:
    provider: ollama
    tag: chat
    tools: '{{ tool_node }}'
    model: llama3.2 # qwen2.5
    temperature: 0.3
  

workflow_react:
  initializer: conditional_graph
  data:
    inline:
      name: ReactWorkflow
      input_mapping:
        messages: query
      schema:
      - name: messages  # schema field name
        field_type: messages
        default: []
        operator: add
        required: true
      - name: is_last_step  # schema field name
        field_type: bool
        default: false
      - name: output  # llm output from ai message
        field_type: str
        required: false
      vertices:
      - name: llm_node
        agent: '{{ llm_with_tools }}'
        next: branch_0
        input_mapping: messages  # pop `messages` from schema
        output_mapping:
          messages: # output  # map llm output to `messages`
          output: # output    # map llm output to `output`
      - name: branch_0
        default: __end__
        branchs:
        - conditions:
          # a trick to check if it's the end of workflow, tool calling wihout output
          - property: output
            value: ''
          next: tools_node
      - name: tools_node
        agent: '{{ tool_node }}'
        next: llm_node

# python cli.py -c workflow_react.yaml -i workflow_react -q "Trump's recent news?" -I query -O output